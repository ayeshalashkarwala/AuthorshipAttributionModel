{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import snscrape.modules.twitter as sntwitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = []\n",
    "for i,tweet in enumerate(sntwitter.TwitterSearchScraper('from:LilTunechi').get_items()):\n",
    "    if i>1000:\n",
    "        break\n",
    "    t.append([tweet.content])\n",
    "tweets_df = pd.DataFrame(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_df.to_csv('LilTunechi_task1.csv', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Going üÜô on #AmazonMusicLive stage TONIGHT!! tw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GO PACK GO!!!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ü§ôüèæ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tf wrong w me playin w 12 like dat?!!? Idk but...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GO PACK GO!!!!!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Happy Birthday Ms Linda!!!! @lindacohn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Jets beat the Bills   Dat man Carton bout to b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>RIP to the season we should‚Äôve gotten rid of 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>GO PACK GO!!!!!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Roll tide??????? Nahhhh roll one tf up for dem...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0\n",
       "0  Going üÜô on #AmazonMusicLive stage TONIGHT!! tw...\n",
       "1                                      GO PACK GO!!!\n",
       "2                                                 ü§ôüèæ\n",
       "3  Tf wrong w me playin w 12 like dat?!!? Idk but...\n",
       "4                                    GO PACK GO!!!!!\n",
       "5             Happy Birthday Ms Linda!!!! @lindacohn\n",
       "6  Jets beat the Bills   Dat man Carton bout to b...\n",
       "7  RIP to the season we should‚Äôve gotten rid of 1...\n",
       "8                                    GO PACK GO!!!!!\n",
       "9  Roll tide??????? Nahhhh roll one tf up for dem..."
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('LilTunechi_task1.csv', header=None)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "def removing_emojis(tweet):\n",
    "    regrex_pattern = re.compile(pattern = \"[\"\n",
    "                u\"\\u23cf\"\n",
    "                u\"\\u23e9\"\n",
    "                u\"\\u231a\"\n",
    "                u\"\\u3030\"\n",
    "                u\"\\ufe0f\"\n",
    "                u\"\\u200d\"\n",
    "                u\"\\u2600-\\u2B55\"\n",
    "                u\"\\u2640-\\u2642\"\n",
    "                u\"\\U0001F600-\\U0001F64F\"  \n",
    "                u\"\\U0001F300-\\U0001F5FF\" \n",
    "                u\"\\U000024C2-\\U0001F251\"\n",
    "                u\"\\U0001f926-\\U0001f937\"\n",
    "                u'\\U00010000-\\U0010ffff'\n",
    "                u\"\\U0001F680-\\U0001F6FF\"\n",
    "                u\"\\U0001F1E0-\\U0001F1FF\"\n",
    "                u\"\\U00002702-\\U000027B0\"\n",
    "                \"]+\", flags = re.UNICODE)\n",
    "    \n",
    "    return regrex_pattern.sub(r'',tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "file=open('stop_words.txt','r')\n",
    "stopWords = file.read()\n",
    "punct =  r'[^ \\\\t\\w\\.]'\n",
    "spaces = r\"\\s{2,}\" \n",
    "http_links = r'http\\S+'\n",
    "digits = r'[0-9]'\n",
    "username = r'@[A-Za-z0-9_]+'\n",
    "hashtags = r'#[A-Za-z0-9_]+'\n",
    "www_links = r'www.\\S+'\n",
    "\n",
    "\n",
    "df[0]=df[0].str.lower()\n",
    "df = df[0].apply(removing_emojis)\n",
    "df = df.replace(to_replace = http_links, value = ' ', regex = True)\n",
    "df = df.replace(to_replace = stopWords, value = '', regex = True)\n",
    "df = df.replace(to_replace=  digits, value='',regex=True)\n",
    "df = df.replace(to_replace = r'\\\"\\\"', value = '', regex = True)\n",
    "df = df.replace(to_replace = www_links, value = ' ', regex = True)\n",
    "df = df.replace(to_replace = username, value = ' ', regex = True)\n",
    "df = df.replace(to_replace = hashtags, value = ' ', regex = True)\n",
    "df = df.replace(to_replace = punct, value = '', regex = True)\n",
    "df = df.replace(to_replace = spaces, value = ' ', regex = True)\n",
    "df = df.replace(to_replace = r'\\.', value = '', regex = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.dropna(how='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    going on stage tonight twitch aint ready for t...\n",
       "1                                           go pack go\n",
       "2                                                     \n",
       "3    tf wrong w me playin w like dat idk buthow bou...\n",
       "4                                           go pack go\n",
       "5                             happy birthday ms linda \n",
       "6    jets beat the bills dat man carton bout to be ...\n",
       "7    rip to the season we shouldve gotten rid of be...\n",
       "8                                           go pack go\n",
       "9    roll tide nahhhh roll one tf up for dem tigers...\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('LilTunechi_task2.csv', index=False, header=False)\n",
    "cean_csv = pd.read_csv('LilTunechi_task2.csv')\n",
    "cean_csv = cean_csv.dropna()\n",
    "cean_csv.to_csv('LilTunechi_task2.csv', index=False, header=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_csv = pd.read_csv('LilTunechi_task2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tf wrong w me playin w like dat idk buthow bou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>go pack go</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>happy birthday ms linda</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>jets beat the bills dat man carton bout to be ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rip to the season we shouldve gotten rid of be...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>go pack go</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>roll tide nahhhh roll one tf up for dem tigers...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>go pack go</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>go pack fkn go</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>new interview with my brodie more to it</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              tweets\n",
       "0  tf wrong w me playin w like dat idk buthow bou...\n",
       "1                                         go pack go\n",
       "2                           happy birthday ms linda \n",
       "3  jets beat the bills dat man carton bout to be ...\n",
       "4  rip to the season we shouldve gotten rid of be...\n",
       "5                                         go pack go\n",
       "6  roll tide nahhhh roll one tf up for dem tigers...\n",
       "7                                         go pack go\n",
       "8                                     go pack fkn go\n",
       "9           new interview with my brodie more to it "
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_csv.columns = ['tweets']\n",
    "clean_csv.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(clean_csv['tweets'], test_size=0.2, shuffle=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vocabulary(data):\n",
    "    words = []\n",
    "    for i in data:\n",
    "        i = str(i)\n",
    "        a = i.split()\n",
    "        for j in a:\n",
    "            words.append(j)\n",
    "    word = np.array(words)\n",
    "    vocab = np.unique(word)\n",
    "    return vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a' 'aa' 'aaaaaaaaaaaaaaaaahhhhhhhhhhhhhh' ... 'z' 'zane' 'zlife']\n"
     ]
    }
   ],
   "source": [
    "vocab = vocabulary(train)\n",
    "print(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bag_of_words(data, train):\n",
    "    bow = []\n",
    "    vocab = vocabulary(train)\n",
    "    for i in data:\n",
    "        v = np.zeros(len(vocab))\n",
    "        i = str(i)\n",
    "        a = i.split()\n",
    "        for k in a:\n",
    "            not_found_vocab = True\n",
    "            for j in range(len(vocab)):\n",
    "                if k == vocab[j]:\n",
    "                    not_found_vocab = False\n",
    "                    v[j] +=1\n",
    "            if not_found_vocab == True:\n",
    "                v = v + 1\n",
    "        bow.append(v)\n",
    "    return bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = bag_of_words(train,train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "[1. 0. 0. ... 0. 0. 0.]\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "[2. 0. 0. ... 0. 0. 0.]\n",
      "[0. 0. 0. ... 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(train_features[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_features = bag_of_words(test, train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "[7. 7. 7. ... 7. 7. 7.]\n",
      "[5. 5. 5. ... 5. 5. 5.]\n",
      "[4. 4. 4. ... 4. 4. 4.]\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "[8. 8. 8. ... 8. 8. 8.]\n",
      "[4. 4. 4. ... 4. 4. 4.]\n",
      "[0. 0. 0. ... 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(test_features[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2020"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = vocabulary(train) #ambient dim\n",
    "len(vocab)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2544f68d75d6e9977f8a2bc33fee835a3b984a77d5098b3bab72bd18626085c9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
